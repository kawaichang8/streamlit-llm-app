import os
import traceback
import streamlit as st
from dotenv import load_dotenv

# ===== æ—©ã‚ã«ãƒšãƒ¼ã‚¸ãƒ¡ã‚¿ã¨ã€Œèµ·å‹•æ¸ˆã¿ã€ã®ç›®å°ã‚’å‡ºã™ =====
st.set_page_config(page_title="LLMã‚¢ãƒ—ãƒªï¼ˆå°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ä»˜ãï¼‰", page_icon="ğŸ¤–")
st.write("âœ… ã‚¢ãƒ—ãƒªèµ·å‹•: ã“ã“ã¾ã§æç”»ã§ãã¦ã„ã‚Œã°ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã¯OK")

# ===== ä»¥é™ã§ä¾‹å¤–ãŒå‡ºãŸã‚‰UIã«å¿…ãšè¡¨ç¤ºã™ã‚‹ =====
def show_exception(e: Exception):
    st.error("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚å³ã®è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.exception(e)
    st.code("".join(traceback.format_exception(type(e), e, e.__traceback__)))

try:
    load_dotenv()  # .env ã‚’èª­ã‚€
    api_key = os.getenv("OPENAI_API_KEY")

    # ---- ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆLangChainã®OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼‰----
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import SystemMessage, HumanMessage

    st.title("ğŸ¤– LLMã‚¢ãƒ—ãƒªï¼ˆå°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ä»˜ãï¼‰")
    st.write("å…¥åŠ›ã—ãŸè³ªå•ã«å¯¾ã—ã¦ã€é¸ã‚“ã å°‚é–€å®¶ã®è¦–ç‚¹ã§å›ç­”ã—ã¾ã™ã€‚")

    # APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯ï¼ˆç„¡ã‘ã‚Œã°UIã«è­¦å‘Šï¼‰
    if not api_key:
        st.warning("OPENAI_API_KEY ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.env ã‹ Streamlit ã® Secrets ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # --- å°‚é–€å®¶ã®ç¨®é¡ ---
    experts = {
        "å¿ƒç†å­¦è€…": "ã‚ãªãŸã¯å¿ƒç†å­¦ã®å°‚é–€å®¶ã§ã™ã€‚äººé–“ã®æ„Ÿæƒ…ã‚„è¡Œå‹•ã«ã¤ã„ã¦æ·±ãç†è§£ã—ã€å„ªã—ãçš„ç¢ºã«åŠ©è¨€ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚",
        "çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ": "ã‚ãªãŸã¯çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ“ã‚¸ãƒã‚¹æˆ¦ç•¥ã‚„çµ„ç¹”æ”¹å–„ã«ã¤ã„ã¦è«–ç†çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚",
        "ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼": "ã‚ãªãŸã¯ã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚åƒãæ–¹ã‚„ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã«ã¤ã„ã¦å‰å‘ããªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚"
    }

    expert_choice = st.radio("ã©ã®å°‚é–€å®¶ã«ç›¸è«‡ã—ã¾ã™ã‹ï¼Ÿ", list(experts.keys()))
    user_input = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", height=100, placeholder="ä¾‹ï¼‰åœ¨å®…å‹¤å‹™ã§é›†ä¸­åŠ›ã‚’ä¸Šã’ã‚‹ã‚³ãƒ„ã¯ï¼Ÿ")

    def get_llm_response(expert: str, query: str) -> str:
        # LangChainã®OpenAIãƒ©ãƒƒãƒ‘ï¼ˆåˆ†é›¢ç‰ˆï¼‰
        llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7, openai_api_key=api_key)
        msgs = [SystemMessage(content=experts[expert]), HumanMessage(content=query)]
        resp = llm.invoke(msgs)  # â† .invoke ã‚’ä½¿ã†ï¼ˆæ–°APIï¼‰
        return resp.content

    if st.button("é€ä¿¡"):
        if not user_input.strip():
            st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
                try:
                    answer = get_llm_response(expert_choice, user_input)
                    st.subheader("ğŸ’¡ å›ç­”")
                    st.write(answer)
                except Exception as e:
                    show_exception(e)

except Exception as e:
    show_exception(e)
